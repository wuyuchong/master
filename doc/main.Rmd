---
title: "基于数据挖掘算法的企业财务指标对未来成长性的预测研究"
output:
  word_document:
    toc: yes
    toc_depth: 2
    fig_caption: yes
    reference_docx: template.docx
csl: chinese-gb7714-2005-numeric.csl
bibliography: reference.bib
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.pos = 'H', echo = FALSE, warning = FALSE, message = FALSE, cache = FALSE)
# base_family = 'STXihei'
library(rmarkdown)
library(knitr)
library(tidyverse)
library(scales)
library(magrittr)
dat = read.csv('../data/data_for_model.csv', header = TRUE)
code_name = read.csv('../data/code_name.csv')
dictionary = read.csv('dictionary.csv')
percent_round = function(x){
  scales::percent(x, accuracy = 1L)
}
N = length(unique(code_name$industry))
industry_table = code_name %>% 
  count(industry) %>%
  filter(industry != '') %>% 
  mutate(percent = percent(n / nrow(code_name))) %>%
  arrange(desc(percent))
# processed = mutate(dat, diffRevenue = ifelse(diffRevenue > 0, 1, 0))
# processed = filter(processed, fin_year == 2020)
# table(processed$diffRevenue)
# processed = dat[!is.na(dat$roeAvg) & !is.na(dat$diffPNI), ]
```

\newpage

# 内容摘要{-}

> word 模版页眉需要更改

\

**关键词**： 量化交易 \ \ \ 低频交易 \ \ \ 机器学习 \ \ \ 深度神经网络 \ \ \ 财务指标

\newpage

# ABSTRACT{-}

**KEY WORDS**: quantitative trading \ \ \ low frequency trading \ \ \ machine learning \ \ \ deep neural network \ \ \ financial indicators

\newpage

# 绪论

## 研究背景

投资者常用净利润和主营业务收入的同比增长率衡量企业的成长性，单纯使用净利润或主营业务收入衡量成长性都可能会有失公允：单纯企业净利润上升可能不是由于主营业务的上涨带来的，而是通过减少费用或非经常性收益获得利润增长，不能反应真实的成长性；单纯主营业务收入的上升可能并不能有效转化为净利润的上涨，投资者常用“增收不增利”来形容这种情况，也不能有效反映企业的成长性。因此衡量企业成长性，需要将净利润和主营业务收入两个指标结合起来看。一般来说，投资者对净利润最为看重，因为其关系到每股净收益，影响了公司的分红情况，企业的赢利性对股价的影响很大。投资者对主营业务收入的关注则会稍微低一些，一般情况下仅要求主营业务随净利润有所增长即可。

## 研究意义

在对企业进行基本面研究时，业内普遍认为企业的财务指标与其未来的成长性具有关联，比如：成长性高的企业具备较高的 PE / PB / PS / ROE，较低的存活周转天数、应收账款与预收账款比、负债率等等。然而，当期财务指标与企业未来的成长性关联并不是完全线性的。目前在学界对该方面进行探讨和验证的研究较少，更少有研究通过企业的财务指标对未来成长性进行预测。我们使用主营业务收入、归属母公司净利润等指标来衡量公司未来的成长性，通过企业过去的财务指标表现情况预测其未来的成长性。

## 研究思路及方法

学习到财务指标与企业未来成长性的潜在关系

我们拟研究财务指标和未来成长性（主营业务收入、归属母公司净利润等）之间的关系，同时依托机器学习算法使用T年的财务指标预测T+1年的营收与利润（包括绝对值与增长率）。我们使用公司的年报财务指标作为自变量，由于数据更新频率低，我们抛弃传统的时间序列处理方法，将 2007 年至 2021 年间 A 股所有上市企业的所有年份经过处理后视为同等的观测，使用（T – 1）年的年报的财务数据（于 T 年披露）和 T 年基准日的估值指标对 T 年的年报的营收和利润的绝对值和增长率（于 T + 1 年披露）进行拟合和预测。样本量约为6万（4000 家 15 年），变量个数约为 50。
我们将使用多种机器学习算法进行预测，同时使用深度学习进行神经网络的训练，运用异常值处理、正则化、dropout 技术、提前终止技术、学习率优化、增减隐藏层等模型参数调节和优化手段。

## 研究内容及框架

拟通过研究企业的财务指标和其未来主营业务收入、归属母公司净利润等成长性相关指标之间的关系，使用机器学习算法对企业未来的成长性进行预测。通过与同行业企业比较的方式验证预测结果的准确性和可应用性，给出成长性较高的企业的财务指标特征，并给出未来各行业成长性最高的企业名单。拟达成的预期效果为：预测营收和利润增长率最高的 TOP 5 / 10 / 20 的企业均值应显著高于同行业均值。同时我们将比较不同的预测模型和算法的优劣。

## 研究创新

在预测时，我们并不追求预测结果完全准确，这在错综复杂的市场形势下几乎时一件不可能的事情；我们更多地关注同行业企业成长性的横向比较，不关心市场宏观因素，

1. 选题自身具有较高创新性，目前在暂无相同课题。有些研究对企业未来的成长性进行预测，很少有研究通过企业的财务指标对未来成长性进行预测，其中基本没有研究使用大数据视角下多种数据挖掘和机器学习算法进行预测。领域相关的多数文章集中于财务指标对财务舞弊及风险识别预测、财务指标作为因子的股价量化研究。
2. 现有研究对企业成长性研究的范围往往局限于公司所处的政策环境制度、盈利能力、营销模式以及企业资源及能力理论，只对企业的外生因素做了相应解释，很少直接使用数据进行对未来的预测，且预测使用的回归模型拟合能力较差，影响成长性的因素很多，使用简单的线性模型无法真正反映企业未来的趋势。因此我们使用目前较为前沿的机器学习技术进行拟合预测，并比较不同的预测模型和算法的优劣。同时，在拟合过程中，我们使用给出各个财务指标的重要性，并针对重要的特征进行分析。
3. 与大多数量化研究都使用时间序列研究方法不同，因财务指标数据更新频率为年 ^[考虑到季报和半年报的局限性，我们仅使用年报作为财务指标的获取来源，见数据处理部分]  ，我们抛弃了对单一企业财务数据的时间序列处理方法，将所有企业的所有年份经过处理后视为同等的观测值，使用 (T - 1) 年的年报数据的财务数据（于 T 年披露）对 (T + 1) 年主营业务收入和归母净利润进行拟合和预测。
4. 由于企业的主营业务收入和归母净利润受影响的因素错综复杂，我们不追求个体企业预测的准确性，仅评价组合的效果。单纯使用财务指标得到主营业务收入和归母净利润的精确预测值既不合理也不现实，但我们可以根据财务指标对企业成长性的预测值排序来构造企业组合，因此在本研究中也无需将宏观指标加入模型。只要预测营收和利润增长率最高的 TOP 5 / 10 / 20 的企业均值显著高于同行业均值，模型即具备现实意义。

# 文献综述

## 企业成长性的衡量指标

国外学者的研究中，Delmar（1997）发现大部分文献使用企业的营业收入作为企业成长性的衡量指标，另有部分文献使用几种混合指标衡量企业成长。Garnsey（2006）认为可以用投资资金人力等投入指标、资本资产等价值指标或销售额等产出指标来衡量企业成长。Garnesy和Hefferman（2006）等人采用二维法，将公司未来成长性划分为持续成长以及中断成长。即当公司面对困难或机遇时，管理层经过权衡后预测公司会持续成长还是中断成长。当竞争激烈时，如果公司不能在竞争中提升地位，则公司会处于维持或收割状态，即中断成长，采取收割措施时，可以从市场中返回部分现金，有利于企业更好进行资金配置管理。Dean（2009）认为可以用销售额、员工人数、利润、资产、股权来衡量企业成长。Leona（2010）发现1997年至2008年的文献中，41.8%的文献使用营业收入来衡量企业成长，27.3%的文献采用就业指标来衡量企业成长。

国内学者的研究中，朱和平（2004）利用AHP层次分析法从公司的财务潜力、人力资本质量、市场公关能力、技术创新能力四个方面选取了20个指标对企业的成长性进行评价。魏文兰（2014）构建了企业成长的财务评价体系，包括盈利能力、偿债能力、营运能力、现金流量等指标。官金华、常有新（2015）利用营业收入增长率这一指标来衡量企业的成长性。

## 企业成长性的影响因素

国外学者的研究中，Hoig（1998）发现企业的关键决策对企业成长具有重要影响。Krugman（1991）发现由于运输成本、采购资源、客户群体位置等原因的影响，公司成长性受其所处地理位置影响。Brealey（2000）发现企业融资的难易程度对公司的决策和成长存在影响，当企业债务融资过高时，成长性通常较低。

国内学者的研究中，张炳坤（1998）根据企业所处阶段的不同，使用生命周期，将企业划分为起步、成长、成熟和衰退四个类别，从外部因素以及内部因素的对企业成长的影响因素进行了分析。官金华、常有新（2005）则先通过因子分析法对企业成长性因素进行分类，随后又利用多元回归得出结论，企业的运营能力会显著影响其成长性。谢文君（2016）发现企业的财务结构会影响企业的融资难易度，从而影响企业的成长性，同时发现创新对于企业增长具有正向促进作用。

## 企业成长性的预测

当前，国内外有关企业成长性预测的研究较少，但仍然有一些与此相关的工作，如对于企业收入和现金流进行预测。Nabil等人研究了45家不同行业的沙特公司的当前收益和现金流以及收益分解来预测未来经营现金流的能力。此外，Hu等人利用历史的会计收益和现金流信息，使用时间及空间序列技术来预测未来的资本现金流走向。在该项工作中，Hu等人利用胡志明市242家非金融行业上市公司的数据，预测了未来的现金流。

国内也有许多研究者对企业的盈利及现金流等指标进行了预测。王丹萌等人从两方面对企业的盈利数据进行了预测，一是利用与Huu等人类似的时间序列分析技术根据2000余家餐饮类企业一年的盈利数据提出了基于LSTM神经网络作为盈利预测模型：另一个方法则是根据线上点评网站上用户的评价信息对商家的盈利能力进行预测。平安琪等人从“语言学”的角度出发，根据上市企业年报中管理层讨论和分析本年度经营情况时的语调对企业的盈利能力进行预测。林莉（2009）等人使用近三年销售收入增长率、净利润增长率、雇员增长率等指标，利用主成分分析法（PCA）对公司未来成长性进行预测，为企业发展提高参考，但此方法假设没有信息损失，前提条件较为严格。张玉明（2011）等人使用BP神经网络方法对企业成长性进行预测，输入指标考虑了企业的盈利能力、成长潜力、生存状态等方面，将30家公司的数据作为训练集，将评估结果与专家分析结果对比，表明两者间误差较小。林榅荷（2016）使用了灰色理论方法对文化企业的成长性进行预测，利用一阶灰色预测模型对企业3年间的成长数据进行建模及预测，取得了不错的成果，但数据样本量较少，且未考虑定性指标的影响。

## 数据挖掘算法

数据挖掘算法发展历史悠久，算法丰富多样，在此我们仅叙述新兴的以神经网络为代表的机器学习算法。在1943年，Warren McCulloch提出了由输入层、隐藏层、输出层组成的网络结构，这被广泛认为是神经网络的雏形。随后在20世纪六十年代，Frank Rosenblatt给出了感知机的概念，用算法及数学公式定义了神经网络模型，对机器学习产生了较大影响。从20世纪八十年代开始，机器学习理论开始迅速发展。1984年，Hinton和Rumelhart给出BP神经网络的概念，使得感知机逐渐回到了人们的视线中。在1989年，卷积神经网络由美国学者LeCun以及Yann提出，并给出了基于反向传播的训练方式，在英文识别方向取得了较好的效果。在1995年，支持向量机SVM和Adaboost算法分别被Vapnik以及Freund等人提出，代表着核技术以及集成学习算法开始逐渐崭露头角。而在二十一世纪初，由Breiman等人提出随机森林算法，因其能够并行计算且具有抗拟合能力至今仍在机器学习领域被大量使用。在2006年，Hinton和Salakhutdinov提出深度学习Deep Learning模型，引入了多隐藏层的结构，成为深度学习领域的里程碑。

各类数据挖掘方法被广泛运用在各种预测问题上，并取得了优秀的效果。国外学者 Fan 等使用支持向量机的分类方法选择出可能有超常表现的个股，得出一个等权重的组合，在五年期获得超过澳大利亚股票市场基准指数 71% 的回报率。Singh 等人展示了深度学习能够提升股票价格预测的准确性，并且实验得到深度神经网络的实际收益与预测收益之间的相关系数比径向基函数神经网络高 17.1％，比递归神经网络高 43.4％。Takeuchi 将深度学习应用到趋势交易策略中，使用了堆叠约束玻耳兹曼机从个股历史价格中提取特征，得到一个增强的动量交易策略，取得了原始趋势基准的成绩。

## 财务指标的量化研究

曾卓斐进行了基于基本面的 Alpha 策略的量化研究，摒弃了传统以收益率作为目标的训练方法，创新地以市净率为目标，且比较了不同学习器的拟合效果，构建了一套表现优秀的 Alpha 策略，美中不足的是以市净率为目标的方法在实际金融市场的可应用性稍微较弱。杨世林使用市净率、市盈率、市销率、市净率、ROA、ROE 6 个较为经典常用的财务指标，构建了一套多因子策略，回测显示策略的年化率达到 16.1%（基准年化率 8.5%）。王晓翌使用在巴菲特的“烟蒂“价值投资理论基础上，使用 5 个财务指标，构建了一个多因子策略。与基准的沪深 300 指数相比，该策略的 Alpha 值达到 12%。

# 数据来源和处理方式 

## 数据获取

使用两种主流的股票数据库 akshare ^[https://www.akshare.xyz] 和 baostock ^[http://baostock.com] 逐一获取 A 股所有股票 2007-2022 年的估值指标数据、已发布的财报财务指标数据，原始数据获取共 1.1 GB，之后进行合并计算处理等整理工作。 ^[指标计算方式详见附录]

由于剔除已退市企业会造成“来自未来信息的泄漏”，为避免该逆向筛选的发生，我们仍然将已知退市的股票的历史信息纳入了我们后续的分析和模型中。

我们共获取4892家上市公司的数据，涵盖了29个申万一级行业分类，其中机械设备、化工、医药生物和电子行业的占比最多。 ^[每个申万行业个股数量及占比见附录]

```{r}
dictionary %>% 
  select(指标类型, 指标, 指标名称) %>% 
  kable(caption = '指标一览')
```

## 数据处理

A股所有上市企业每年发布四份本公司的财务报表，分别为年报、半年报、一季报和三季报。与年报不同，季报和半年报无需被审计，因此许多公司在编制一季报、半年报和三季报时严谨性较差；而年报的编制则较为详实，可信度较高，且进行了更加仔细频繁的校验和调整。

季报和中报的可操纵空间较大，部分公司存在先发布业绩预报，利用季报和中报做数据调整，以此实现业绩超预期来进行股价炒作的现象。然而，对于年报，这种做法则较少，一方面是因为年报受到审计的限制，调整余地小，另一方面是伪造年报的法律风险较大。同时，季报和中报受到季节周期的影响较大，大部分企业的营收等指标在一年中不同季度的分布经常是不均匀的，且在不同行业间差异较大。

因此，我们仅使用年报披露的财务数据作为研究对象。所有的企业都在每年的 1-4 月份披露前一年的年报，因此在每年的 5 月份的首个交易日所有企业上一年的年报均已披露。由于估值指标会收到股价的影响，因此我们统一将每年 5 月的首个交易日作为基准日，使用该日的估值指标（PE、PS、PB），此日至下一年 5 月的首个交易日作为一个年周期。

将 2007 年至 2021 年间 A 股所有上市企业的所有年份经过处理后视为同等的观测，使用（T – 1）年的年报的财务数据（于 T 年披露）和 T 年基准日的估值指标对 T 年的年报的营收和利润的绝对值和增长率（于 T + 1 年披露）进行拟合和预测。样本量约为6万（4000 家 15 年），变量个数约为 50。

```{r}
table = read.csv('dataset_describe.csv')
kable(table, caption = '数据集划分年份')
```

我们将整个数据集划分为 6 个集，其中训练集、验证集和测试集使用 2007 - 2018 年 ^[此处年份指的是自变量年份] 的数据随机划分，训练集占比 80%，验证集占比 10%，测试集占比 10%，目的主要为使三个集合的标签分布基本保持一致，以获得效果较好的模型。

我们使用训练集中的数据进行训练，在训练的过程中，通过将迭代得到的参数应用在验证集上进行预测，得出验证集上的损失指标，以此损失指标作为训练过程中的反馈以调整模型参数。由于测试集是训练过程中从未直接或间接接触的数据，待模型参数调整完毕后，使用测试集来评价模型的最终效果。

回测集使用 2019 年的数据，作用在于评判依靠“过去”的数据建立的模型在“未来”的数据集上的拟合效果，与测试集不同，回测集中的数据已经超出了训练集所能接触到的年份，因此可以评价模型是否拥有足够强的泛化能力。

效应集用来评价模型解决研究问题的实际能力，使用 2020 年的数据，我们对模型预测出的营收和利润增长率最高的 TOP 5 / 10 / 20 的企业均值与同行业均值进行比较，以得到在真实情况下模型的效果。

预测集使用 2021 年财务指标（财报于 2022 年披露），对2022年企业成长性（目前尚未披露2022年年报）进行预测。

# 实证

- 知乎文章

第一层次是简单回归，包括双变量、多元回归，基本计量问题（共线性、异方差、自相关）的处理；第二层次更专业点儿，包括模型设定误差检验与模型修正、特殊数据类型（时间序列、虚拟变量、面板数据等）的模型选择和处理、联立方程、VEC模型、VAR模型、条件异方差模型等；第三层次包括有序因变量、面板VAR、神经网络、分位数模型、季节调整模型等等。

## 描述性统计

## 差异性分析

## 相关性分析

# 预测

## 预测方法

我们首先进行二分类预测，使用财务指标预测主营业务收入的涨跌。

## 评价指标

在所有环节中，我们使用十折交叉验证取平均的方式对各种模型和方法进行评估。

### 分类

在成长性预测二分类问题中，由于主营业务收入和归母净利润多数企业的多数年份上升，样本不平衡，因此准确率（Accuracy）、精确率（Precision）、召回率（recall）仅作为观测指标，不作为各模型和方法的评价指标，

为衡量不平衡样本下各模型的表现情况，我们使用精确率和召回率的加权调和平均 F1 值来评价模型。

$$ F 1=\frac{2}{\frac{1}{\text { Precision }}+\frac{1}{\text { Recall }}} $$

同时，使用 ROC 曲线与 X 轴围成的面积除以总面积得到的 AUC 值作为另一个重要的评判指标。

$$ P(f(p)>f(n))=\frac{\Sigma_{p, n}(i f(f(p)>f(n))}{\Sigma_{p, n}} $$

另一个评判指标为 Matthews 相关性系数（MCC），它度量真实值和预测值之间的相关性，取值在 -1 到 1 之间，值为 0 时代表这是个随机分类器。

$$ M C C=\frac{T P \times T N-F P \times F N}{\sqrt{(T P+F P)(T P+F N)(T N+F P)(T N+F N)}} $$

Kappa 统计量（Cohen 1960） @Cohen1960A 最初用来评估两个评价者结果的一致性，它考虑到了由偶然情况引起的准确性误差。

$$\mathrm{Kappa}=\frac{O-E}{1-E}$$

其中：

* 0 代表预测值与实际值不同，1 代表相同。
* E 代表根据混淆矩阵边缘计数得出的期望准确性
* Kappa 取值范围为：[-1, 1]
* Kappa 值 0.30 到 0.50 之间代表合理的一致性（Agresti 2002） 

### 定量

MAE	MSE	RMSE	R2	RMSLE	MAPE

均方误差计算了测试集上累积误差平方的平均。

$$ MSE_{\text {test}}= \frac{1}{m} \sum_{i=1}^m\left(y_{\text {test }}^{(i)}-\hat{y}_{\text {test }}^{(i)}\right)^2 $$

由于均方误差可能导致量纲问题，对其进行开方得到均方根误差：

$$ RMSE_{\text {test}}= \sqrt{\frac{1}{m} \sum_{i=1}^m\left(y_{\text {test }}^{(i)}-\hat{y}_{\text {test }}^{(i)}\right)^2}=\sqrt{M S E_{\text {test}}} $$

由于均方根误差先对误差进行平方的累加后再开方，放大了较大误差之间的差距，因此我们还使用平均绝对误差进行模型的评估：

$$ MAE_{\text {test}}= \frac{1}{m} \sum_{i=1}^m\left|y_{\text {test }}^{(i)}-\hat{y}_{\text {test }}^{(i)}\right| $$

同时，RMSE适用于预测分布较为平均的预测值。当预测值范围很大时，RMSE容易受到较大值主导。此时即使较小值预测准确，错误预测较大值时，RMSE容易虚高。 相应地，存在较差算法对较大值预测准确，但是较小值偏差严重时，RMSE很可能会被低估。为了解决这个问题，可以先取对数后再求RMSE，即为均方根对数误差。

$$RMSLE_{\text {test}}=\sqrt{\frac{1}{m} \sum_{i=0}^{m-1}\left(\log _e\left(1+y_i\right)-\log _e\left(1+\hat{y}_i\right)\right)^2}$$

平均绝对百分比误差（MAPE）对相对误差较为敏感，不易受到目标变量全局缩放的影响。

$$MAPE_{\text {test}}=\frac{1}{m} \sum_{i=0}^{m-1} \frac{\left|y_i-\hat{y}_i\right|}{\max \left(\epsilon,\left|y_i\right|\right)}$$

上述的衡量方法都不存在上下限，我们引入 $R^2$ 对模型进行评价，其上限为1，越接近1代表模型越好，0.5附近则代表模型效果基本等同于随机猜测。

$$ R^2=1-\frac{S S_{\text {residual }}}{S S_{\text {total }}} \quad \begin{array}{c}
\text { (Residual Sum of Squares) } \\
\text { (Total Sum of Squares) }
\end{array} = 1-\frac{\sum_i\left(\hat{y}^{(i)}-y^{(i)}\right)^2}{\sum_i\left(\bar{y}-y^{(i)}\right)^2} = 1-\frac{\operatorname{MSE}(\hat{y}, y)}{\operatorname{Var}(y)}$$


# 预处理

## 缺失值处理

经检查，由于年报披露未完全、部分指标无法计算出等原因，存在一些企业的部分财务指标常有缺失的情况，且各公司缺失的指标互不相同。多数机器学习算法要求所有指标的值不应是缺失的，因此我们使用不同的处理方式进行处理。

对于因变量（主营业务及净利润）缺失的样本，我们将其进行直接删除；对于自变量财务指标部分缺失的样本，由于直接删除存在缺失值的样本将导致可用样本量明显减少（有效样本量由 XX 减少至 XX），数据的样本较为珍贵，我们使用插补的方法对缺失值进行处理。

相比于单变量插补法（univariate imputation）使用缺失值所在变量的其它非缺失值进行插补，多变量插补法（multivariate imputation）使用可用的所有变量进行目标缺失值的估计填补。@2017mice 对每个财务指标，当进行该指标的缺失值填补时，该指标作为因变量，其它的财务指标作为自变量，使用 lightgbm 模型进行拟合后预测出缺失值进行填补。

[Nearest neighbors imputation](https://scikit-learn.org/stable/modules/impute.html)

“mean”: Impute with mean of column.

“median”: Impute with median of column.

“mode”: Impute with most frequent value.

“knn”: Impute using a K-Nearest Neighbors approach.

[公式]

```{r}
table = read.csv('output/classification/preprocess_imputation.csv')
kable(table, digits = 3, caption = '不同插值方法在主营业务收入二分类预测下的效果比较')
```

```{r}
table = read.csv('output/regression/preprocess_imputation.csv')
kable(table, digits = 3, caption = '不同插值方法在归母净利润定量预测下的效果比较')
```

## 异常值处理与标准化

对于财务指标，许多比率型指标由于计算方式的原因容易产生极端值。例如，市盈率的计算方式市值与净利润之比，在净利润处于盈亏平衡线附近时，市盈率绝对值接近0，将导致市盈率极端大或极端小。

标准化能消除不同财务指标方差大小的影响。鉴于财务指标的特殊性，我们不使用常规的标准化方法，而是对每个指标使用该样本数据在同指标中的分位距代替其原值。

```{r, out.width='25%', fig.align='center', fig.cap = "库克距离图"}
knitr::include_graphics("figure/regression/Cooks Distance.png")
```

同时，我们使用库克距离剔除异常值，库克距离兼顾残差大小和杠杆率：

$$D_i=\frac{\left(y_i-\hat{y}_i\right)^2}{(m+1) s^2}\left[\frac{h_i}{\left(1-h_i\right)^2}\right]$$

其中，$\left(y_i-\hat{y}_i\right)^2$ 表示第 $i$ 个样本点的残差，$s$ 表示估计的标准差，$h_i$ 表示第 $i$ 个样本点的杠杆率，$m$ 为变量个数。

当样本点超过 $F_{(m, n-m-1)}$ 分布的中位数时说明该样本点具有较大的影响。

为了减少异常值对模型训练的影响，我们剔除了训练集和验证集中库克距离过大的样本，且为了尽可能地贴近现实，提高模型的通用性，在测试集和效应集上，我们并没有对异常值进行处理。

> 引用库克距离的文章

```{r}
table = read.csv('output/classification/preprocess_normalize.csv')
kable(table, digits = 3, caption = '异常值处理与标准化在主营业务收入二分类预测下的效果比较')
```

## 特征变换

<事前正态性检验待补充>

特征变换改变了变量的分布使得变换后数据呈现一个合适的正态分布，可以有效解决模型的异方差性问题。

对于自变量，我们使用 yeo-johnson 和 quantile 方法进行特征变换，对于 quantile 变换方法，由于它并不是线性的，会改变原有变量间的线性相关性。

由于财务指标存在负值，Box-Cox 变换不能符合要求，我们使用幂变换方法 Yeo-Johnson 对自变量进行处理，以减小指标的异方差性，使各项财务指标的概率密度函数的形态逼近正态分布，有利于各项机器学习模型的拟合。

> 可引用百度参考资料 https://baike.baidu.com/item/Yeo-Johnson%E5%8F%98%E6%8D%A2/23578212?fr=aladdin

当随机变量为正值：

$$ Y=\left\{\begin{array}{ll}
\log (X+1) & \text { if } \lambda=0, X \geq 0 \\
\frac{(X+1)^\lambda-1}{\lambda} & \text { if } \lambda \neq 0, X \geq 0
\end{array}\right. $$

当随机变量为负值：

$$ Y=\left\{\begin{array}{ll}
-\log (-X+1) & \text { if } \lambda=2, X \leq 0 \\
\frac{-\left[(-X+1)^{(2-\lambda)}-1\right]}{2-\lambda} & \text { if } \lambda \neq 2, X \leq 0
\end{array}\right. $$

其中 $\lambda$ 为变换系数，通过机器学习算法进行学习。

对于因变量，由于我们进行二分类预测，因此不进行特征变换。

```{r}
table = read.csv('output/classification/preprocess_transformation.csv')
kable(table, digits = 3, caption = '不同特征变换方式在主营业务收入二分类预测下的效果比较')
```

```{r}
table = read.csv('output/regression/preprocess_transformation.csv')
kable(table, digits = 3, caption = '不同特征变换方式在归母净利润定量预测下的效果比较')
```

## 数据倾斜修正

对于主营业务收入，上涨和下跌的样本分别为 XX% ，对于归母净利润，上涨和下跌的样本分别为 XX%。预测目标变量体现出较强的不平衡性，因此我们使用 SMOTE 过采样技术进行数据倾斜的修正。

由于各年份下跌的企业占比较少，部分模型可能无法非常有效地学习到决策边界，我们尝试使用 SMOTE 过采样方法平衡类分布。

SMOTE 方法从少数类中随机选择样本，通过最邻近算法找到特征空间中样本周围的 k 个样本（k通常取5），在每两个样本之间随机选择点创建新样本。

SMOTE 方法虽然解决了样本的不平衡问题，但如果创建的新样本之间有很强的重叠性时，可能会使产生额外的噪音影响模型的效果。

[过采样方法](https://imbalanced-learn.org/stable/index.html)

<过采样可以做的东西有很多>

```{r}
table = read.csv('output/classification/preprocess_imbalance.csv')
kable(table, digits = 2, caption = '不同过采样方法在不同模型下的交叉验证效果比较')
```

> 需要补充预处理之前和预处理之后总体效果比较

# 多模型比较

> 要介绍为什么选择这些模型

我们使用十折交叉验证的方式进行多个机器学习模型的比较。
^[阿里云服务器 Xeon 8 核 CPU 32G 内存]

```{r}
table = read.csv('output/classification/comparison.csv')
table = select(table, -Accuracy)
kable(table, digits = 2, caption = '主营业务收入二分类预测各模型的交叉验证效果比较')
```

```{r}
table = read.csv('output/regression/comparison.csv')
kable(table, digits = 2, caption = '归母净利润定量预测各模型的交叉验证效果比较')
```

# 特征工程

## 分类变量处理

我们使用独热编码的方式处理非数值型变量，在我们的数据中，我们将‘申万一级行业分类’处理为哑变量。

对于企业名称这一变量，由于企业数量上千，如果进行独热编码处理将导致变量个数过多，这样处理后数据集的高维稀疏性质将导致许多机器学习模型的速度和准确率受到很大影响。因此我们使用聚类方法先对企业名称进行聚类，之后使用聚类标签代替特征的原始值。

> 对多重共线性的处理

## 特征交互

暂时不用

## 特征选择

# 模型调参

> early stop asha

```{r, out.width='25%', fig.align='center', fig.cap = "Catboost 模型深度与准确率曲线"}
knitr::include_graphics("figure/classification/Validation Curve.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "Catboost 模型深度与准确率曲线"}
knitr::include_graphics("figure/regression/Validation Curve.png")
```

## 最优模型

```{r, out.width='25%', fig.align='center', fig.cap = "KS 曲线"}
knitr::include_graphics("figure/classification/KS Statistic Plot.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "Gain 曲线"}
knitr::include_graphics("figure/classification/Gain Chart.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "Lift 曲线"}
knitr::include_graphics("figure/classification/Lift Chart.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "模型在测试集上的 ROC 曲线"}
knitr::include_graphics("figure/classification/AUC.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "二分类辨别阈值图"}
knitr::include_graphics("figure/classification/Threshold.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "精确率和召回率曲线"}
knitr::include_graphics("figure/classification/Precision Recall.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "混淆矩阵"}
knitr::include_graphics("figure/classification/Confusion Matrix.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "分类指标"}
knitr::include_graphics("figure/classification/Class Report.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "svm 模型决策边界"}
knitr::include_graphics("figure/classification/Decision Boundary.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "主营业务收入二分类预测 Morris 敏感度变量重要性"}
knitr::include_graphics("figure/classification/MSA msa.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "归母净利润定量预测 Morris 敏感度变量重要性"}
knitr::include_graphics("figure/regression/MSA msa.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "主营业务收入二分类预测变量重要性"}
knitr::include_graphics("figure/classification/Feature Importance.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "归母净利润定量预测变量重要性"}
knitr::include_graphics("figure/regression/Feature Importance.png")
```

> 变量重要性 TOP 3 模型都要出
> 特征工程过程涉及选择生成有效模型所需的最小特征，因为模型包含的特征越多，它就越复杂（数据越稀疏），因此模型对方差的误差越敏感。消除特征的常用方法是描述它们对模型的相对重要性，然后消除弱特征或特征组合并重新评估以确定模型在交叉验证期间是否更好。


```{r, out.width='25%', fig.align='center', fig.cap = "在测试集上的拟合图"}
knitr::include_graphics("figure/regression/Prediction Error.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "在测试集上的拟合残差图"}
knitr::include_graphics("figure/regression/Residuals.png")
```

> 残差是目标变量（y）的观测值与预测值（ŷ）之间的差异

## 模型校准

<模型校准的理论待补充>

逻辑回归输出天然具有概率性质，例如模型的输出值为0.2表示该预测样本有20%的概率为正样本。但是对于其他许多二分类算法而言（例如支持向量机），模型的输出并不能代表真实概率，需要借助模型校准算法，使其输出与真实分布具有一致性。

我们使用 reliability 曲线评估模型预测概率，根据模型的输出将样本分成10个桶，即预测为0至0.1的样本归为一个桶，预测为0.1至0.2的样本归为一个桶等等，以这10个桶作为横坐标；计算每个桶内的正样本占比作为纵坐标。若reliability曲线靠近对角线则说明模型输出基本代表真实概率。

```{r, out.width='25%', fig.align='center', fig.cap = "校准图（校准前）"}
knitr::include_graphics("figure/classification/Calibration Curve.png")
```

我们使用 Platt 校准算法，利用逻辑回归的输出具有概率的性质，对模型输出值进行校准，将模型输出放入逻辑回归中训练，最后将逻辑回归的结果作为模型 $f\left(\mathbf{x}\right)$ 校准结果。首先获取模型在每个样本上的输出  $f\left(\mathbf{x}_1\right), \cdots, f\left(\mathbf{x}_n\right)$，将这些输出与真实标签构建成新的数据集 $\left(f\left(\mathbf{x}_1\right), y_1\right), \cdots,\left(f\left(\mathbf{x}_n\right), y_n\right)$ ，使用逻辑回归进行训练：

$$P(y=1 \mid f)=\frac{1}{1+\exp (A f+B)}$$

其中 $A,B$ 为训练参数，使用最小化交叉熵损失函数对其进行训练。模型校准结果即为逻辑回归的输出结果，即对于样本 $\mathbf{x}_i$ 而言，模型输出为 $f\left(\mathbf{x}_i\right)$ ，那么在该模型下 $\mathbf{x}_i$ 为正样本的概率为 $P\left(y=1 \mid f\left(\mathbf{x}_i\right)\right)=\frac{1}{1+\exp \left(A f\left(\mathbf{x}_i\right)+B\right)}$ 。

```{r, out.width='25%', fig.align='center', fig.cap = "校准图（校准后）"}
knitr::include_graphics("figure/classification/before/Calibration Curve.png")
```

## 集成模型

> Bagging:减少 variance
> boosting: 减少 bias
> stacking:增强预测效果

使用 Bagging（bootstrap aggregation）算法对数据集进行等概率采样后，创建 10 个相同类别的模型（Estimators）进行拟合，在预测时通过 10 个模型结果投票得出最终结果，这种方法可以显著减小模型结果的方差。


Boosting 算法相较 Bagging 算法，每一次抽样的样本分布不同，通过创建一系列区分顺序的预测器，排在前面的预测器拟合数据后，给予错误预测的样本更高权重，由后续的预测器修复误差。通过把一系列弱学习器进行串联，组成一个强学习器。

```{r}
table = read.csv('output/classification/ensemble.csv')
kable(table, digits = 3, caption = '对主营业务收入的分类预测单模型集成学习效果比较')
```

使用模型比较排名前三的 CatBoost、Light Gradiant Boosting、Extreme Gradient Boosting 模型分别进行 Bagging 集成算法的搭建，发现三种模型相比原模型在各个评价指标上均有一定的提升。由于排名前三的模型本身便运用了 Boosting 的原理，因此进一步进行 Boosting 后不会有效果的提升。

在对归母净利润的定量预测中，由于随机森林算法本身并没有使用 Boosting 思想，因此在 Boosting 处理后 $MSE$、$RMSE$ 有所下降，$R^2$ 有所上升。

```{r}
table = read.csv('output/regression/ensemble.csv')
kable(table, digits = 3, caption = '对归母净利润的定量预测单模型集成学习效果比较')
```

相较于 Bagging 模型使用多个相同模型拟合不同的采样数据，Blending 使用多个不同的模型拟合相同的全体数据，同样适用投票法得出最终的预测结果。

相比 Blending，Stacking 并不直接用简单的投票法决定最终预测结果，还使用一个额外的模型（在此我们使用 lightGBM）进一步拟合各个模型的预测值。

第一步，有T个不同模型，根据财务指标数据，各自独立训练。每个模型输出结果为 $h_t$ ，其中t= 1,2,3...T
第二步，根据每个模型预测，创建新的训练集，训练集的数据（X）是预测结果,Y是实际结果。
第三步，再训练一个classifier，这里叫meta-classifier，来从各个预测中再生成最后预测。

[可以画一个小示意图]


```{r}
table = read.csv('output/classification/stack.csv')
kable(table, digits = 3, caption = '对主营业务收入的分类预测多模型集成学习效果比较')
```

使用模型比较排名前三的 CatBoost、Light Gradiant Boosting、Extreme Gradient Boosting 模型分别进行 Blending 和 Stacking 集成算法的搭建，发现三种模型相比原模型在各个评价指标上均有一定的提升。

Blending 有两种方式，一种使用预测概率作为投票法的依据，另一种使用预测的二分类结果作为投票法的依据，实践表明，第一种方式的效果在主营业务收入的预测中效果较好。

对于 Stacking 模型，业界常有两种方法：

1. 使用所有的训练数据对第一层多个模型进行k折交叉验证，每个模型在训练集上都有一个预测值，然后将这些预测值做为新特征对第二层的模型进行训练；
2. 将原始的训练集先分成两部分，70%的数据作为新的训练集，剩下30%的数据作为测试集，第一层在训练集上训练多个模型，预测测试集上的企业成长性，在第二层里直接用测试集在第一层预测的结果做为新特征继续训练。

第一种方法由于不需要交叉验证，耗时相较于第二种方法较短，且由于两层模型使用的数据不同，避免了信息泄漏问题；然而，其划分方式决定了可用数据量较小，容易产生过拟合现象，且没有第二种方法稳健。

实践表明，在进行主营业务收入和归母净利润的预测中，第一种方法效果远好于第二种，可能是第二种方法信息泄漏问题较严重导致其在测试集上表现不佳。

```{r}
table = read.csv('output/regression/stack.csv')
kable(table, digits = 3, caption = '对归母净利润的定量预测多模型集成学习效果比较')
```

# shap

除了 logistic 回归，大多数的机器学习常被认为是“黑盒模型”，然而我们可以使用 shap 值解释模型给出的预测值和企业财务指标的关系。我们将所有的财务指标视为模型的贡献特征，通过计算一个财务指标加入到模型时的边际贡献，取该特征在所有不同特征序列的情况下边际贡献的均值，即为该特征的 SHAP 值。

> Permutation importance很不错，因为它用很简单的数字就可以衡量特征对模型的重要性。但是它不能handle这么一种情况：当一个feature有中等的permutation importance的时候，这可能意味着这么两种情况： - 1：对少量的预测有很大的影响，但是整体来说影响较小； - 2：对所有的预测都有中等程度的影响。

> 引用 shap 论文

< moris 变量重要性的理论待补充>

> 净利润增长率 毛利率和净利率：毛利率越高代表销售额转化为利润的效率越高，未来销售额的提升很容易反映到利润增长上。毛利率和净利率的差异在于净利扣除了各项费用，过高的净利率通常意味着销售费用占比较低，即利润的获取对销售费用投入的依赖较小，未来很难通过强行增加销售费用的方式提升净利润。高成长性的企业往往具有高毛利率、高销售费用占比、低净利率的特征


```{r, out.width='25%', fig.align='center', fig.cap = "贵州茅台2020归母净利润预测解释图"}
knitr::include_graphics("figure/regression/2019shap600519.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "贵州茅台2021归母净利润预测解释图"}
knitr::include_graphics("figure/regression/2020shap600519.png")
```

使用2019年的财务指标预测茅台股份2020年归母净利润增长率，预测给出26%，实际为13%；预测给出2021年归母净利润增长率为19%，实际为12%。模型认为使得未来利润下滑的主要因素是净资产收益率、净利润总营收占比、销售净利率，即对于模型从市场上的所有公司中学习到盈利占比营收或资产比例很大时，很可能已经发展到了成熟阶段，多数情况下未来净利润难以继续保持增长的态势，所以这三项财务指标过高很可能会削弱未来的成长态势。然而模型还是给出了茅台超过基准值12个百分点的预测增长率，原因在于茅台的较高市净率、市销率和主营业务收入规模。相对于其净资产和销售额，较高的估值代表了投资者对茅台未来利润增长的看好。同时，茅台的销售毛利率较高意味着未来只要投入更多的销售资源，销售额的增长很容易反映到利润增长上。

```{r, out.width='25%', fig.align='center', fig.cap = "贵州茅台2020主营业务收入预测解释图"}
knitr::include_graphics("figure/classification/2019shap600519.png")
```

```{r, out.width='25%', fig.align='center', fig.cap = "贵州茅台2021主营业务收入预测解释图"}
knitr::include_graphics("figure/classification/2020shap600519.png")
```

使用2019年的财务指标预测2020年主营业务收入涨跌二分类，预测给出为增长可能性为95.2%，实际主营业务收入也有所增长；使用2020年的财务指标，预测2021年主营业务收入增长可能性为95.8%，模型给出的判断主要依据市净率、权益乘数、当前营收规模。贵州茅台当前营收规模很高，非常高的市净率代表投资者对公司质地的认可，较低的权益乘数代表其财务杠杆率低，现有融资少，未来进一步扩张的潜能大。

```{r, out.width='25%', fig.align='center', fig.cap = "包钢股份2020主营业务收入预测解释图"}
knitr::include_graphics("figure/classification/2019shap600010.png")
```

使用2019年的财务指标预测包钢股份2020年主营业务收入涨跌二分类，预测给出为下滑，实际主营业务收入也有所下滑，模型做出该判断的主要依据为权益乘数、市盈率、经营性现金净流量占比净利润、总资产同比增长率。包钢股份2019年市盈率绝对值非常大，处于盈亏平衡状态，不太符合高成长性公司的一般特征。其利息占比息税前利润过大，说明企业的负债相对于其盈利情况较重，进一步借款改善经营状况的空间很小，负债严重影响企业未来成长。在负债率较高的情况下，资产2019年处于负增长状态，说明企业的资产流失、折旧严重，影响到未来营收的增长。经营性现金净流量为负值，代表企业开展主营业务运营能力较差，在没有新突破的情况下，未来成长能力弱。同时，较大的权益乘数代表股东投入资本占比较小，财务杠杆已经很大，进一步加大杠杆的空间较小，影响未来成长性。

```{r, out.width='25%', fig.align='center', fig.cap = "包钢股份2021主营业务收入预测解释图"}
knitr::include_graphics("figure/classification/2020shap600010.png")
```

模型给出2021年包钢股份主营业务收入不再下滑，开始上涨，与实际情况相符。从2020年财务指标看，相比上一年，2020年盈利情况较好，滚动市盈率不再被模型认为是减分项，同时由于经营情况较好，经营性现金流量占比净利润较高，此项也不再影响未来的成长性。模型认为资产负债率、速动比率、已获利息倍数这几项指标是判定其未来增长的关键指标。较高的资产负债率和较低的速动比率代表了企业的扩张态势，虽然同时会给企业带来较大的利息费用影响净利润增长，但未来营业收入增长可能性较大。正值且较小的已获利息倍数表明了企业的举债规模较大且具备偿还能力，模型学习认为此类企业未来成长性较好。

```{r, out.width='25%', fig.align='center', fig.cap = "递归特征消除效果图"}
# knitr::include_graphics("figure/classification/rfe.png")
```

> 递归特征消除（RFE）是一种特征选择方法，它训练模型并删除最弱的特征（或多个特征），直到达到指定数量的特征。特征按模型的coef_或feature_importances_属性排序，并通过递归消除每个循环的少量特征，RFE尝试消除模型中可能存在的依赖性和共线性。RFE需要保留指定数量的特征，但事先通常不知道有多少特征有效。为了找到最佳数量的特征，交叉验证与RFE一起用于对不同的特征子集进行评分，并选择最佳评分特征集合。RFECV可视化绘制模型中的特征数量以及它们的交叉验证测试分数和可变性，并可视化所选数量的特征。该图显示了理想的RFECV曲线，当捕获三个信息特征时，曲线跳跃到极好的准确度，然后随着非信息特征被添加到模型中，精度逐渐降低。阴影区域表示交叉验证的可变性，一个标准偏差高于和低于曲线绘制的平均精度得分。在这个例子中，我们可以看到选择了19个特征，尽管在大约5个特征之后模型的f1分数似乎没有太大改善。选择要消除的特征在确定每个递归的结果中起着重要作用；修改步骤参数以在每个步骤中消除多个特征可能有助于尽早消除最差特征，增强其余特征（并且还可用于加速具有大量特征的数据集的特征消除）。


> 模型验证用于确定模型对其已经过训练的数据的有效性以及它对新输入的泛化程度。为了测量模型的性能，我们首先将数据集拆分为训练和测试，将模型拟合到训练数据上并在保留的测试数据上进行评分。为了最大化分数，必须选择模型的超参数，以便最好地允许模型在指定的特征空间中操作。大多数模型都有多个超参数，选择这些参数组合的最佳方法是使用网格搜索。然而，绘制单个超参数对训练和测试数据的影响有时是有用的，以确定模型是否对某些超参数值不适合或过度拟合。


# 效果

经过预处理、特征工程、模型调参、集成模型、模型比较等步骤，我们使用表现最佳的模型，将测试集的数据也加入模型中重新进行训练，将训练后的模型应用于效应集上，观察模型的实际应用效果。

我们呈现出各行业预测主营业务收入上升的公司组合的平均实际营业收入增长率，与该行业所有公司平均营业收入增长率进行比较。

```{r}
table = read.csv('output/classification/portfolio.csv')
names(table)[1] = '一级行业'
table = mutate_if(table, is.numeric, percent_round)
kable(table, caption = '各行业预测增长或下降的公司组合与同行业所有公司主营业务收入比较')
```

结果表明，在每个申万一级行业下，基本都呈现出

我们呈现出各行业预测成长性较好和较差的 TOP X 公司组合的平均实际营业收入增长率，同时与该行业所有公司平均营业收入增长率进行比较。

```{r}
table = read.csv('output/regression/portfolio.csv')
names(table)[1] = '一级行业'
table = mutate_if(table, is.numeric, percent_round)
kable(table, caption = '各行业预测公司组合与同行业所有公司归母净利润增长率比较')
```

# 预测

> 待补充


# 参考文献{-}

\

<div id="refs"></div>

\newpage

# 附录{-}


## 数据概览

```{r}
dictionary %>% 
  select(指标名称, 指标计算方式) %>% 
  kable(caption = '指标的计算方式')
```

```{r}
# table = str(dat)
# kable(table)

# table = as.data.frame(summary(dat))
# table = t(table)
# kable(table)
```

```{r}
names(industry_table) = c('行业', '股票数量', '占比')
kable(industry_table, caption = "申万行业个股数量及占比")
```
